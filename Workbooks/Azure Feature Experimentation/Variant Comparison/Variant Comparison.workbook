{
    "version": "Notebook/1.0",
    "items": [
      {
        "type": 1,
        "content": {
          "json": "# Feature evaluation via A/B testing -- monitoring and results\r\n---\r\n\r\nThis workbook is designed for Azure AppConfig A/B tests. \r\n\r\n- Overview features and variants with recent assignment activity, to ensure test features are being assigned as expected.\r\n- Select specific feature and baseline variant to review how each test variant compares across your configured metrics."
        },
        "name": "intro text"
      },
      {
        "type": 9,
        "content": {
          "version": "KqlParameterItem/1.0",
          "crossComponentResources": [
            "value::all"
          ],
          "parameters": [
            {
              "id": "9a6e815b-22c5-4fd1-a260-9ed52c977ffa",
              "version": "KqlParameterItem/1.0",
              "name": "Source",
              "type": 5,
              "description": "Select the log analytics workspace containing your application experiment data",
              "isRequired": true,
              "query": "where type == \"microsoft.operationalinsights/workspaces\"\r\n| project id\r\n| order by id contains \"exp\" desc",
              "crossComponentResources": [
                "value::all"
              ],
              "typeSettings": {
                "additionalResourceOptions": [],
                "showDefault": false
              },
              "timeContext": {
                "durationMs": 86400000
              },
              "queryType": 1,
              "resourceType": "microsoft.resourcegraph/resources"
            }
          ],
          "style": "above",
          "queryType": 1,
          "resourceType": "microsoft.resourcegraph/resources"
        },
        "name": "Source Parameter"
      },
      {
        "type": 9,
        "content": {
          "version": "KqlParameterItem/1.0",
          "crossComponentResources": [
            "{Source}"
          ],
          "parameters": [
            {
              "id": "c947fd85-40a6-485d-8145-086ebaeb80ca",
              "version": "KqlParameterItem/1.0",
              "name": "_feature",
              "label": "Feature",
              "type": 2,
              "description": "Select an AppConfig feature for variant comparison",
              "query": "AppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated\r\n| summarize start = min(TimeGenerated), end = max(TimeGenerated) by Feature\r\n| order by end desc\r\n| project Feature",
              "crossComponentResources": [
                "{Source}"
              ],
              "typeSettings": {
                "additionalResourceOptions": [],
                "showDefault": false
              },
              "timeContext": {
                "durationMs": 2592000000
              },
              "queryType": 0,
              "resourceType": "microsoft.operationalinsights/workspaces"
            },
            {
              "id": "a85aa232-1141-4100-87bd-c4d70a18444d",
              "version": "KqlParameterItem/1.0",
              "name": "_control",
              "label": "Control Variant",
              "type": 2,
              "query": "AppEvents\r\n| where Name == \"FeatureEvaluation\"\r\n| where Properties.VariantAssignmentReason == \"Percentile\" and Properties.FeatureName==\"{_feature}\"\r\n| project Variant = tostring(Properties.Variant), TimeGenerated\r\n| summarize start = min(TimeGenerated), end = max(TimeGenerated) by Variant\r\n| order by end desc\r\n| project Variant",
              "crossComponentResources": [
                "{Source}"
              ],
              "typeSettings": {
                "additionalResourceOptions": [],
                "showDefault": false
              },
              "timeContext": {
                "durationMs": 2592000000
              },
              "queryType": 0,
              "resourceType": "microsoft.operationalinsights/workspaces"
            }
          ],
          "style": "above",
          "queryType": 0,
          "resourceType": "microsoft.operationalinsights/workspaces"
        },
        "name": "parameters - 6"
      },
      {
        "type": 9,
        "content": {
          "version": "KqlParameterItem/1.0",
          "crossComponentResources": [
            "{Source}"
          ],
          "parameters": [
            {
              "id": "ef6f6313-8917-4f38-97bf-e8048217cb23",
              "version": "KqlParameterItem/1.0",
              "name": "Metrics",
              "type": 2,
              "multiSelect": true,
              "quote": "'",
              "delimiter": ",",
              "query": "ComputeScorecardAB_LatestExperiment(feature_name=\"{_feature}\",control_variant=\"{_control}\", lookback=30d)\r\n| where MetricDisplayName != \"Sample size\"\r\n| distinct MetricDisplayName",
              "crossComponentResources": [
                "{Source}"
              ],
              "typeSettings": {
                "additionalResourceOptions": [
                  "value::all"
                ],
                "selectAllValue": "all",
                "showDefault": false
              },
              "defaultValue": "value::all",
              "queryType": 0,
              "resourceType": "microsoft.operationalinsights/workspaces"
            },
            {
              "id": "d953ebfa-a7df-4461-b0dc-9c668fc4a675",
              "version": "KqlParameterItem/1.0",
              "name": "AlphaThreshold",
              "label": "Strength of Evidence",
              "type": 2,
              "typeSettings": {
                "additionalResourceOptions": [],
                "showDefault": false
              },
              "jsonData": "[{\"label\":\"Highly Stat Sig\", \"value\":0.001},{\"label\": \"Stat Sig\",\"value\":0.05},{\"label\": \"All\",\"value\":1}]",
              "value": "1"
            },
            {
              "id": "73b6acec-2f3d-4df3-a027-98493402f258",
              "version": "KqlParameterItem/1.0",
              "name": "EffectType",
              "label": "Treatment Effect",
              "type": 2,
              "multiSelect": true,
              "quote": "'",
              "delimiter": ",",
              "typeSettings": {
                "additionalResourceOptions": [
                  "value::all"
                ],
                "selectAllValue": "all",
                "showDefault": false
              },
              "jsonData": "[\"Changed\",\"Improved\",\"Degraded\",\"Inconclusive\"]",
              "defaultValue": "value::all"
            }
          ],
          "style": "above",
          "queryType": 0,
          "resourceType": "microsoft.operationalinsights/workspaces"
        },
        "name": "Metric Parameters"
      },
      {
        "type": 1,
        "content": {
          "json": "### Most recent A/B results for treatment variants of Feature: **{_feature}**, with comparison against control variant: **{_control}**\r\n\r\n\r\nEach metric displays:\r\n-  assessed treatment effect: statistically significant effects are labeled as \"Improved\", \"Degraded\" or \"Changed\" depending on whether the effect direction matches the metric's configured direction of improvement.\r\n- Effect estimated size, as a % lift/drop from control variant.\r\n- Estimate of the margin of error on the effect estimate. Each metric measurement is from a limited sample of potentially noisy data, which guarantee the estimate is not what you'd observe if the feature were exposed to all users. The margin of error gives an approximate bound for how far the estimated effect from this experiment may be from the true effect. Running an experiment for longer duration (or increased traffic allocation) generally lowers the margin of error.\r\n- Control and Treatment metric values: the actual metric value in each variant.\r\n- Interpretability risk level: metrics with very low sample size or other data quality issues can be unreliable. If a metric is flagged with high interpretability risk, we have detected a data quality issue on that metric which prevents it's use for a decision on feature evaluation. More reliable data is needed -- either through higher sample size, or by refining the telemetry logging which contributes to the metric. "
        },
        "name": "metric intro text"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let _MostRecentScorecardResult = ComputeScorecardAB_LatestExperiment(feature_name=\"{_feature}\",control_variant=\"{_control}\", lookback=30d);\r\nlet t = 2.0 ; //rough t score for margin of error\r\nlet buffer = 0.0000000001; // avoid zero denominator\r\nlet alpha_weak = 0.05;\r\n_MostRecentScorecardResult\r\n| where case('all' in ({Metrics}),true, MetricDisplayName in ({Metrics}) ) and case('all' in ({EffectType}), true, TreatmentEffect in ({EffectType})) and case(\"{AlphaThreshold}\" == \"\",true, PValue < todouble(\"{AlphaThreshold}\"))//  abs(ControlMetricValue) >= 0 and PValue < alpha_weak\r\n| extend EstimatedEffect = round(100*(TreatmentMetricValue - ControlMetricValue)/(ControlMetricValue+buffer),2), EstimateMarginOfError = max_of(0.01,round(iff(ControlCount*TreatmentCount > 900, 100* sqrt(pow(TreatmentStandardError,2)+ pow(ControlStandardError,2))*t/(ControlMetricValue+buffer), 100.0)),2), MetricDescription = iff(MetricDescription != \"NA\", MetricDescription,\"\")\r\n| extend Effect_Category = case(PValue >= alpha_weak ,0,\r\n(DesiredDirection ==\"Decrease\" and TreatmentMetricValue > ControlMetricValue) or (DesiredDirection==\"Increase\" and TreatmentMetricValue < ControlMetricValue),-2,\r\n(DesiredDirection ==\"Decrease\" and TreatmentMetricValue < ControlMetricValue) or (DesiredDirection==\"Increase\" and TreatmentMetricValue > ControlMetricValue), +2,\r\n+1)\r\n| extend SampleSize_RiskLevel = min_of(10,round(1+15/log2(min_of(TreatmentCount,ControlCount)))), SignalQuality_RiskLevel = min_of(10,iff(ControlStandardError*TreatmentStandardError==0,5.0, max_of(round(ControlStandardError/ControlMetricValue), round(TreatmentStandardError/TreatmentMetricValue)))), Insights= bag_pack(\"SufficientData\",iff(ControlCount*TreatmentCount < 900, \"Unhealthy. Low sample size\", \"OK\"), \"SignalClarity\",iff(ControlStandardError * TreatmentStandardError == 0 , \"Unhealthy. No variation: potential data quality issue\", iff(max_of(ControlStandardError/ControlMetricValue, TreatmentStandardError/TreatmentMetricValue) > 10, \"Unhealthy. Highly noisy signal\", \"OK\")))\r\n| extend Insight_RiskLevel = case(max_of(SignalQuality_RiskLevel, SampleSize_RiskLevel)>7, \"high\",max_of(SignalQuality_RiskLevel, SampleSize_RiskLevel)>4, \"moderate\",\"low\")\r\n| project MetricDisplayName, TreatmentEffect, Effect_Estimate = strcat( iff(EstimatedEffect>0,\"+\",\"\"), EstimatedEffect,\"%\"), Estimate_MarginOfError = strcat(\"+/-\",EstimateMarginOfError,\"%\"), Control_Value = round(ControlMetricValue,3), Treatment_Value = round(TreatmentMetricValue,3), Interpretation_Warnings = Insight_RiskLevel, PValue ,Insights, TreatmentVariant //ControlMetricValue, TreatmentMetricValue, SignalQuality_RiskLevel, SampleSize_RiskLevel // ControlStandardError, TreatmentStandardError,  , Effect_Risk = \r\n| order by TreatmentEffect asc",
          "size": 3,
          "title": "Metric movements, using selected variant as control.",
          "showExportToExcel": true,
          "queryType": 0,
          "resourceType": "microsoft.operationalinsights/workspaces",
          "crossComponentResources": [
            "{Source}"
          ],
          "gridSettings": {
            "formatters": [
              {
                "columnMatch": "TreatmentEffect",
                "formatter": 18,
                "formatOptions": {
                  "thresholdsOptions": "icons",
                  "thresholdsGrid": [
                    {
                      "operator": "==",
                      "thresholdValue": "Improved",
                      "representation": "success",
                      "text": "{0}{1}"
                    },
                    {
                      "operator": "==",
                      "thresholdValue": "Degraded",
                      "representation": "4",
                      "text": "{0}{1}"
                    },
                    {
                      "operator": "==",
                      "thresholdValue": "Changed",
                      "representation": "1",
                      "text": "{0}{1}"
                    },
                    {
                      "operator": "==",
                      "thresholdValue": "Inconclusive",
                      "representation": "Normal",
                      "text": "{0}{1}"
                    },
                    {
                      "operator": "Default",
                      "thresholdValue": null,
                      "representation": null,
                      "text": "{0}{1}"
                    }
                  ]
                },
                "numberFormat": {
                  "unit": 0,
                  "options": {
                    "style": "decimal"
                  }
                },
                "tooltipFormat": {
                  "tooltip": "Is there a stat-sig change observed in the metric?"
                }
              },
              {
                "columnMatch": "Control_Value",
                "formatter": 0,
                "numberFormat": {
                  "unit": 0,
                  "options": {
                    "style": "decimal"
                  }
                }
              },
              {
                "columnMatch": "Interpretation_Warnings",
                "formatter": 18,
                "formatOptions": {
                  "thresholdsOptions": "icons",
                  "thresholdsGrid": [
                    {
                      "operator": "==",
                      "thresholdValue": "moderate",
                      "representation": "Sev2",
                      "text": "{0}{1}",
                      "tooltipFormat": {
                        "tooltip": "Metric has some issues that may impact it's interpretability. This may include: moderately low sample size, imbalance of sample size between variants, unexpectedly high or low variance."
                      }
                    },
                    {
                      "operator": "==",
                      "thresholdValue": "severe",
                      "representation": "Sev0",
                      "text": "{0}{1}",
                      "tooltipFormat": {
                        "tooltip": "Severe issues: higher quantity of data is required to trust this metric for decision"
                      }
                    },
                    {
                      "operator": "Default",
                      "thresholdValue": null,
                      "representation": "Sev4",
                      "text": "{0}{1}"
                    }
                  ]
                }
              },
              {
                "columnMatch": "PValue",
                "formatter": 5
              },
              {
                "columnMatch": "Insights",
                "formatter": 5
              },
              {
                "columnMatch": "TreatmentVariant",
                "formatter": 5
              }
            ],
            "hierarchySettings": {
              "treeType": 1,
              "groupBy": [
                "TreatmentVariant"
              ],
              "expandTopLevel": true
            },
            "labelSettings": [
              {
                "columnId": "MetricDisplayName",
                "label": "Metric"
              },
              {
                "columnId": "TreatmentEffect",
                "label": "Treatment effect"
              },
              {
                "columnId": "Effect_Estimate",
                "label": "Effect estimate"
              },
              {
                "columnId": "Estimate_MarginOfError",
                "label": "Estimate margin of error"
              },
              {
                "columnId": "Control_Value",
                "label": "Control value"
              },
              {
                "columnId": "Treatment_Value",
                "label": "Treatment value"
              },
              {
                "columnId": "Interpretation_Warnings",
                "label": "Interpretability risk",
                "comment": "Detected danger level of misleading metric result, based on insufficient data quality or quantity."
              }
            ]
          },
          "sortBy": []
        },
        "conditionalVisibility": {
          "parameterName": "_control",
          "comparison": "isNotEqualTo"
        },
        "name": "query - metric values"
      },
      {
        "type": 1,
        "content": {
          "json": "> PARAMETER SELECTION REQUIRED\r\n> \r\n> For variant comparison, select your analytics workspace, feature, and control variant."
        },
        "conditionalVisibility": {
          "parameterName": "_control",
          "comparison": "isEqualTo"
        },
        "name": "text - missing parameters"
      },
      {
        "type": 12,
        "content": {
          "version": "NotebookGroup/1.0",
          "groupType": "editable",
          "items": [
            {
              "type": 1,
              "content": {
                "json": "## Feature A/B assignment status overview\r\n\r\nAn overview of Features with variant assignment activity in past 30 days."
              },
              "name": "text - 1"
            },
            {
              "type": 3,
              "content": {
                "version": "KqlItem/1.0",
                "query": "AppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated, Variant = tostring(Properties.Variant), ETag = tostring(Properties.ETag), TargetId = tostring(Properties.TargetingId)\r\n| make-series AssignmentEvents = count() on TimeGenerated from ago(30d) to now()  step 6h  by Feature, ETag, Variant\r\n| project AssignmentEvents, Feature, ETag, Variant\r\n| join kind = inner (\r\nAppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated, Variant = tostring(Properties.Variant), ETag = tostring(Properties.ETag), TargetId = tostring(Properties.TargetingId)\r\n| summarize EarliestAssignment = min(TimeGenerated), MostRecentAssignment = max(TimeGenerated), TargetingIdEstimatedCount = dcount(TargetId) by Feature, ETag, Variant\r\n| extend DaysSinceLastAssignment = datetime_diff('Day',now(), MostRecentAssignment) ) on Feature, ETag, Variant\r\n| order by DaysSinceLastAssignment asc\r\n| project Feature, ETag, Variant, EarliestAssignment, MostRecentAssignment, AssignmentEvents, TargetingIdEstimatedCount, DaysSinceLastAssignment",
                "size": 0,
        
                "queryType": 0,
                "resourceType": "microsoft.operationalinsights/workspaces",
                "gridSettings": {
                  "formatters": [
                    {
                      "columnMatch": "Feature",
                      "formatter": 1
                    },
                    {
                      "columnMatch": "AssignmentEvents",
                      "formatter": 9,
                      "formatOptions": {
                        "palette": "blue",
                        "customColumnWidthSetting": "50ch"
                      }
                    },
                    {
                      "columnMatch": "TargetingIdEstimatedCount",
                      "formatter": 4,
                      "formatOptions": {
                        "min": 0,
                        "max": 10000,
                        "palette": "blue"
                      }
                    },
                    {
                      "columnMatch": "DaysSinceLastAssignment",
                      "formatter": 18,
                      "formatOptions": {
                        "thresholdsOptions": "icons",
                        "thresholdsGrid": [
                          {
                            "operator": "<=",
                            "thresholdValue": "1",
                            "representation": "uninitialized",
                            "text": "{0}{1}",
                            "tooltipFormat": {
                              "tooltip": "Recent assignment activity"
                            }
                          },
                          {
                            "operator": ">",
                            "thresholdValue": "1",
                            "representation": "stopped",
                            "text": "{0}{1}",
                            "tooltipFormat": {
                              "tooltip": "No recent assignment activity"
                            }
                          },
                          {
                            "operator": "Default",
                            "thresholdValue": null,
                            "representation": "success",
                            "text": "{0}{1}"
                          }
                        ]
                      }
                    },
                    {
                      "columnMatch": "count_",
                      "formatter": 9,
                      "formatOptions": {
                        "palette": "blue"
                      }
                    }
                  ],
                  "hierarchySettings": {
                    "treeType": 1,
                    "groupBy": [
                      "Feature"
                    ],
                    "expandTopLevel": true
                  },
                  "sortBy": [
                    {
                      "itemKey": "EarliestAssignment",
                      "sortOrder": 1
                    }
                  ],
                  "labelSettings": [
                    {
                      "columnId": "EarliestAssignment",
                      "label": "Earliest assignment"
                    },
                    {
                      "columnId": "MostRecentAssignment",
                      "label": "Most recent assignment"
                    },
                    {
                      "columnId": "AssignmentEvents",
                      "label": "30 day assignment volume"
                    },
                    {
                      "columnId": "TargetingIdEstimatedCount",
                      "label": "Sample size (approx)"
                    }
                  ]
                },
                "sortBy": [
                  {
                    "itemKey": "EarliestAssignment",
                    "sortOrder": 1
                  }
                ]
              },
              "name": "query - assigned variants"
            }
          ]
        },
        "name": "group - experiment status"
      }
    ],
    "$schema": "https://github.com/Microsoft/Application-Insights-Workbooks/blob/master/schema/workbook.json"
  }